{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on GeorgeMcIntire Fake or Real News Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs a bags of words model (CountVectorizer), as well as an LSTM on the George Mc dataset. The goal is to establish that our LSTM is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, auc\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = pd.read_csv(\"../data/fakerealnews_GeorgeMcIntire/fake_or_real_news.csv\")\n",
    "fr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Bag of Words - Using text only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words with linear regression gives us 94% accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(fr['text'],np.where(fr['label']=='FAKE', 1, 0), \n",
    "                                                    test_size = .2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 61502\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_data = vectorizer.fit_transform(x_train)\n",
    "test_data = vectorizer.transform(x_test)\n",
    "\n",
    "print(\"Size of the vocabulary:\", train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Logistic Regression -----\n",
      "{'C': 0.04}\n",
      "Logistic accuracy: 94.31728%\n",
      "Logistic accuracy (AUC): 94.29985%\n",
      "--- Confusion Matrix ---\n",
      "[[618  33]\n",
      " [ 39 577]]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logisitc modeling\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "C = {\"C\": [0.00001, 0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 0.8, 1, 1.5, 5, 10]}\n",
    "log_gs = GridSearchCV(log_clf,C)\n",
    "log_gs.fit(train_data, y_train)\n",
    "\n",
    "log_clf_best = LogisticRegression(C=log_gs.best_params_['C'])\n",
    "log_clf_best.fit(train_data, y_train)\n",
    "log_clf_best_predicted = log_clf_best.predict(test_data)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, log_clf_best_predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('----- Logistic Regression -----')\n",
    "print (log_gs.best_params_)\n",
    "print (\"Logistic accuracy: {:2.5f}%\".format(accuracy_score(log_clf_best_predicted, y_test) * 100))\n",
    "print (\"Logistic accuracy (AUC): {:2.5f}%\".format(metrics.auc(fpr,tpr) * 100))\n",
    "\n",
    "# print confusion matrix to identify mistakes\n",
    "print('--- Confusion Matrix ---')\n",
    "print (confusion_matrix(y_test, log_clf_best_predicted))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Bag of Words - Using title and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is the same using title and text. This shows that adding the title doesn't hurt the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr['title_and_text'] = fr['title'] + ' ' + fr['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(fr['title_and_text'],np.where(fr['label']=='FAKE', 1, 0), \n",
    "                                                    test_size = .2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 61750\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_data = vectorizer.fit_transform(x_train)\n",
    "test_data = vectorizer.transform(x_test)\n",
    "\n",
    "print(\"Size of the vocabulary:\", train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Logistic Regression -----\n",
      "{'C': 0.05}\n",
      "Logistic accuracy: 94.31728%\n",
      "Logistic accuracy (AUC): 94.32604%\n",
      "--- Confusion Matrix ---\n",
      "[[612  39]\n",
      " [ 33 583]]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logisitc modeling\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "C = {\"C\": [0.00001, 0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 0.8, 1, 1.5, 5, 10]}\n",
    "log_gs = GridSearchCV(log_clf,C)\n",
    "log_gs.fit(train_data, y_train)\n",
    "\n",
    "log_clf_best = LogisticRegression(C=log_gs.best_params_['C'])\n",
    "log_clf_best.fit(train_data, y_train)\n",
    "log_clf_best_predicted = log_clf_best.predict(test_data)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, log_clf_best_predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('----- Logistic Regression -----')\n",
    "print (log_gs.best_params_)\n",
    "print (\"Logistic accuracy: {:2.5f}%\".format(accuracy_score(log_clf_best_predicted, y_test) * 100))\n",
    "print (\"Logistic accuracy (AUC): {:2.5f}%\".format(metrics.auc(fpr,tpr) * 100))\n",
    "\n",
    "# print confusion matrix to identify mistakes\n",
    "print('--- Confusion Matrix ---')\n",
    "print (confusion_matrix(y_test, log_clf_best_predicted))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.055e+03, 1.757e+03, 3.260e+02, 9.200e+01, 4.500e+01, 3.100e+01,\n",
       "        9.000e+00, 5.000e+00, 6.000e+00, 4.000e+00]),\n",
       " array([3.0000e+00, 8.2070e+02, 1.6384e+03, 2.4561e+03, 3.2738e+03,\n",
       "        4.0915e+03, 4.9092e+03, 5.7269e+03, 6.5446e+03, 7.3623e+03,\n",
       "        8.1800e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See how long a typical new article is, in order to choose max sequence length\n",
    "words = fr['title_and_text'].str.lower().str.split()\n",
    "fr['num_words'] = words.apply(len)\n",
    "# fr['title_and_text'].iloc[0]\n",
    "# plt.hist(fr['num_words'], bins=20)\n",
    "plt.hist(fr[fr['num_words'] < 10000]['num_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply location of GloVe text file, location of data, and max word length of news article\n",
    "glove_filepath = '../models/embeddings/glove.6B.50d.txt'\n",
    "maxSeqLength = 1000 # Lets start with 1000\n",
    "numDimensions = 50  # Of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load GloVe embedding data, and convert it to three useful formats\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    wordsList = []\n",
    "    embeddings = []\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        wordsList.append(word)\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "        embeddings.append(embedding)\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    f.close()\n",
    "    return wordsList, embeddings, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "wordsList, embeddings, model = loadGloveModel(glove_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "def cleanArticle(string):\n",
    "    strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "# Function that takes a news article as an input.\n",
    "# It generates a fixed sequences of integers corresponding to the index of the embedding in the embedding lookup\n",
    "# It caps the number of embedded words (i.e. article length) at maxSeqLength\n",
    "# Words that do not exist in GloVe, will be assigned to a random embedding. In this case, the one at position 39999\n",
    "def getArticleMatrix(article):\n",
    "    articleMatrix = np.zeros(maxSeqLength, dtype='int32')\n",
    "    cleanedArticle = cleanArticle(article)\n",
    "    split = cleanedArticle.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        if indexCounter==maxSeqLength:\n",
    "            break\n",
    "        try:\n",
    "            articleMatrix[indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            articleMatrix[indexCounter] = 399999 #Vector for unkown words\n",
    "    return articleMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the articles ** Heads up, This takes a little over 20 minutes!! (4 vCPUs, 15 GB memory)\n",
    "fr['news_embed'] = fr['title_and_text'].apply(getArticleMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_and_text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>news_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "      <td>1301</td>\n",
       "      <td>[81, 86, 9332, 291289, 1655, 2588, 25007, 7, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>460</td>\n",
       "      <td>[1716, 0, 5159, 1600, 923, 3512, 1805, 209, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "      <td>440</td>\n",
       "      <td>[2932, 4, 242, 4, 1035, 6, 7536, 3, 7823, 95, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>419</td>\n",
       "      <td>[13574, 1453, 13, 10360, 20454, 6, 3946, 98, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>326</td>\n",
       "      <td>[0, 903, 3, 50, 196, 738, 37, 1417, 3072, 47, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                      title_and_text  num_words  \\\n",
       "0  You Can Smell Hillary’s Fear Daniel Greenfield...       1301   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...        460   \n",
       "2  Kerry to go to Paris in gesture of sympathy U....        440   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...        419   \n",
       "4  The Battle of New York: Why This Primary Matte...        326   \n",
       "\n",
       "                                          news_embed  \n",
       "0  [81, 86, 9332, 291289, 1655, 2588, 25007, 7, 3...  \n",
       "1  [1716, 0, 5159, 1600, 923, 3512, 1805, 209, 15...  \n",
       "2  [2932, 4, 242, 4, 1035, 6, 7536, 3, 7823, 95, ...  \n",
       "3  [13574, 1453, 13, 10360, 20454, 6, 3946, 98, 0...  \n",
       "4  [0, 903, 3, 50, 196, 738, 37, 1417, 3072, 47, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miketp333/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate news df to use\n",
    "news_df = fr\n",
    "\n",
    "# Embedded word vector lookup. Convert from list to numpy array\n",
    "wordVectors = np.asarray(embeddings)\n",
    "\n",
    "# Split news articles and classification into test and train sets\n",
    "newsVectors, newsVectors_test, classVector, classVector_test = \\\n",
    "    train_test_split(news_df['news_embed'],\n",
    "                     np.where(fr['label']=='FAKE', 1, 0),\n",
    "                     test_size = .2,\n",
    "                     random_state = 1)\n",
    "\n",
    "newsVectors, newsVectors_test, classVector, classVector_test = \\\n",
    "    np.asarray(newsVectors), \\\n",
    "    np.asarray(newsVectors_test), \\\n",
    "    np.asarray(classVector), \\\n",
    "    np.asarray(classVector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch(ids, label):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    # Get indexes of real and fake news and shuffle them\n",
    "    real = list(np.where(label==0)[0])\n",
    "    fake = list(np.where(label==1)[0])\n",
    "    random.shuffle(real)\n",
    "    random.shuffle(fake)\n",
    "    \n",
    "    # Number to pull for each of thet two classifications\n",
    "    num = int(batchSize/2)\n",
    "    \n",
    "    # If batch size an even number. Split evenly fake and real\n",
    "    if (batchSize % 2 == 0):\n",
    "        comb = real[0:num] + fake[0:num]\n",
    "        # Repeat the labels\n",
    "        labels = [[0,1]] * num + [[1,0]] * num\n",
    "    # If batch size an odd number. Split evenly fake and real, and add 1 fake\n",
    "    else:\n",
    "        comb = real[0:num] + fake[0:num]\n",
    "        comb = comb + fake[num:num+1]\n",
    "        labels = [[0,1]] * num + [[1,0]] * num\n",
    "        labels = labels +  [[1,0]]\n",
    "    \n",
    "    for i in range(len(comb)):\n",
    "        arr[i] = ids[comb[i]]\n",
    "          \n",
    "    return arr, np.asarray(labels)\n",
    "\n",
    "\n",
    "# Use all test data. Make sure batch size = length(test data) because I did not make batch size dynamic\n",
    "def getTestBatch(ids, label):\n",
    "    labels = []\n",
    "    num_test = len(label)\n",
    "    arr = np.zeros([num_test, maxSeqLength])\n",
    "    for i in range(num_test):\n",
    "        arr[i] = ids[i]\n",
    "        if label[i] == 0:\n",
    "            labels.append([0,1])\n",
    "        else:\n",
    "            labels.append([1,0])\n",
    "            \n",
    "    return arr, np.asarray(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - 3 min (4 vCPUs, 15 GB memory)\n",
    "batchSize = len(classVector_test)\n",
    "numClasses = 2\n",
    "# number_of_layers = 2\n",
    "lstmUnits = 100\n",
    "iterations = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    " \n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### single layer\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits, forget_bias=0.0)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)  # Add dropout or not?\n",
    "value, final_h_ = tf.nn.dynamic_rnn(lstmCell, tf.cast(data,tf.float32), dtype=tf.float32)\n",
    "\n",
    "\n",
    "# ### multiple layers\n",
    "\n",
    "# def lstm_cell():\n",
    "#     return tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "\n",
    "# stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(number_of_layers)])\n",
    "# initial_h = stacked_lstm.zero_state(batchSize, tf.float32)\n",
    "# value, final_h = tf.nn.dynamic_rnn(stacked_lstm, tf.cast(data,tf.float32), initial_state=initial_h, dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.0, shape=[numClasses]))\n",
    "# Transpose rows and columns (0-->1, 1-->0, 2-->2)\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miketp333/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 126700000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=prediction)) \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-16 03:46:12.267475\n",
      "saved to models/pretrained_lstm.ckpt-999\n",
      "2018-11-16 03:49:20.196415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Set up Tensorboard\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Train model\n",
    "for i in range(iterations):\n",
    "            \n",
    "    nextBatch, nextBatchLabels = getTrainBatch(newsVectors, classVector)\n",
    "    \n",
    "#     if i == 0:\n",
    "#         h = sess.run(initial_h, {input_data: nextBatch})\n",
    "        \n",
    "    # Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    #Save the network every 10,000 training iterations, or on last iteration\n",
    "    if ((i % 10000 == 0 and i != 0) or i == iterations - 1):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "writer.close()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-999\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 45.93527913093567\n",
      "[[526  90]\n",
      " [580  71]]\n",
      "Accuracy: 0.4711917916337806\n"
     ]
    }
   ],
   "source": [
    "# View results on test data\n",
    "nextBatch, nextBatchLabels = getTestBatch(newsVectors_test, classVector_test)\n",
    "print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "predictions = sess.run(prediction, {input_data: nextBatch})\n",
    "predictions = [p[0] > p[1] for p in predictions]\n",
    "classVector_test\n",
    "print(confusion_matrix(classVector_test, predictions))\n",
    "print(\"Accuracy:\", sum(classVector_test==predictions) / len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
