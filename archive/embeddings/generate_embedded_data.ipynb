{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook converts all of the words in the news data to vectors, using pre-trained GloVe vectors. We will start by using 50 dimension embeddings created from Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased). The file (glove.6B.50d.txt) can be downloaded here: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply location of GloVe text file, dimension of embedding used, and max word length of news article\n",
    "# We will want all of our articles to be the same number of words long. Some articles will be padded with 0 at the end,\n",
    "# and others will be cut off at maxSeqLength\n",
    "glove_filepath = 'glove.6B/glove.6B.50d.txt'\n",
    "datapath = 'C:/Users/mpowers/w266/w266finalproject/data/fakeNewsDatasets_Perez-Rosas2018'\n",
    "dim = 50\n",
    "maxSeqLength = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n",
      "[-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n",
      "['the', ',', '.', 'of', 'to']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GloVe vectors\n",
    "import numpy as np\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    wordsList = []\n",
    "    embeddings = []\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        wordsList.append(word)\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "        embeddings.append(embedding)\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    f.close()\n",
    "    return wordsList, embeddings, model\n",
    "\n",
    "# We can access the position of a word in the embedding file using \"wordsList\"\n",
    "# We can access the embedding of a word using \"embeddings\". The position in this will match \"wordlist\"\n",
    "# We can access the embedding of a word using the dictionary \"model\". We will not actually use this, but useful to have.\n",
    "wordsList, embeddings, model = loadGloveModel(glove_filepath)\n",
    "print(model['hello'])\n",
    "print(wordsList[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GloVe embeddings are all lowercase. It does not find an emedding if you accidently use an uppercase letter.\n",
    "# print(model['Hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanArticle(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "# Function that generates fixed sequences of integers corresponding to the embeddings in the embedding lookup\n",
    "def getArticleMatrix(article):\n",
    "    articleMatrix = np.zeros(maxSeqLength, dtype='int32')\n",
    "    cleanedArticle = cleanArticle(article)\n",
    "    split = cleanedArticle.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        if indexCounter==maxSeqLength:\n",
    "            break\n",
    "        try:\n",
    "            articleMatrix[indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            articleMatrix[indexCounter] = 399999 #Vector for unkown words\n",
    "    return articleMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each news file and generate a list with each word replaced with its corresponding index in the GloVe embedding file\n",
    "import os\n",
    "\n",
    "embedded_news = []\n",
    "\n",
    "for dataset_name in ['fakeNewsDataset']:\n",
    "    for news_type in ['fake', 'legit']:\n",
    "        folder = '%s/%s/%s' % (datapath, dataset_name, news_type)\n",
    "        for fname in os.listdir(folder):\n",
    "            filepath = os.path.join(folder, fname)\n",
    "            with open(filepath, 'r', encoding=\"utf8\") as f:\n",
    "                file_data = f.read().split('\\n')\n",
    "                embedded_news.append(getArticleMatrix(' '.join(file_data[0:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3791,   1155,  25058,      6, 399999,   3187,   3791,   1155,\n",
       "        49070,      3,      0,    920,   8775,    172,   2557, 399999,\n",
       "            5,   1551,      3,      0,   3791,   1155,    273,     31,\n",
       "           51,  25058,      6,     26,   1267,   3336,      0, 284841,\n",
       "       399999,   3187,   1155,      5,    423,   8323,    906,     76,\n",
       "           62,     12,    220,    590,    165,    148,     35,    791,\n",
       "            6,      7,   9520,  27478,    964,   1739,   6123,      5,\n",
       "        10711,   2930,    622,      0,    289,   8038,   9388,  20594,\n",
       "        14805,  13376,  29948,   9388,     19,      7,    669,      0,\n",
       "         2196,   8395,      0,    590,    165,      5,    107,     33,\n",
       "         1098,   1034,   1441,      4,      0,   4539,    443,    763,\n",
       "          398,    220,     95,    347,   2255,     33,    114,   1311,\n",
       "           12,     39,     33,  12784,    109,      3,    158,   1267,\n",
       "           49,  16379,   4815,     13,      0,   2087,      3,    201,\n",
       "            3,      0,    638,    479,    840,     32,    287,      4,\n",
       "           30,   1450,      6,      0,    781,    249,      0,    172,\n",
       "          934,     19,      7,   3143,  27799,     10,   1155,     38,\n",
       "           31,     51,    876,     21,    109,   4826,    493,   7001,\n",
       "            3,    134,      7,   4642,  27285,      5,      3,   3648,\n",
       "         6412,    172,   6380,   1155,     31,    456,   2571,   3187,\n",
       "            5,     15, 121250,      6,    493,    687,     19,     29,\n",
       "          880,      3,    197,  14535,      5,  10747,    172,  44460,\n",
       "           13,    659,    493,   9986,    117,   8320,   8364,      5,\n",
       "        10360,    105,      0,  15463,    367,   1155,     31,     52,\n",
       "         4497,  27972,      6,      0,    239,     78,   2189,      3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of one of our embedded news articles\n",
    "# We can feed these into tensorflow, along with \"embeddings\" as the embedding lookup\n",
    "embedded_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37  14  77 728 172   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "37\n",
      "14\n",
      "77\n",
      "77\n",
      "728\n",
      "172\n",
      "[ 5.3074e-01  4.0117e-01 -4.0785e-01  1.5444e-01  4.7782e-01  2.0754e-01\n",
      " -2.6951e-01 -3.4023e-01 -1.0879e-01  1.0563e-01 -1.0289e-01  1.0849e-01\n",
      " -4.9681e-01 -2.5128e-01  8.4025e-01  3.8949e-01  3.2284e-01 -2.2797e-01\n",
      " -4.4342e-01 -3.1649e-01 -1.2406e-01 -2.8170e-01  1.9467e-01  5.5513e-02\n",
      "  5.6705e-01 -1.7419e+00 -9.1145e-01  2.7036e-01  4.1927e-01  2.0279e-02\n",
      "  4.0405e+00 -2.4943e-01 -2.0416e-01 -6.2762e-01 -5.4783e-02 -2.6883e-01\n",
      "  1.8444e-01  1.8204e-01 -2.3536e-01 -1.6155e-01 -2.7655e-01  3.5506e-02\n",
      " -3.8211e-01 -7.5134e-04 -2.4822e-01  2.8164e-01  1.2819e-01  2.8762e-01\n",
      "  1.4440e-01  2.3611e-01]\n",
      "[ 5.3074e-01  4.0117e-01 -4.0785e-01  1.5444e-01  4.7782e-01  2.0754e-01\n",
      " -2.6951e-01 -3.4023e-01 -1.0879e-01  1.0563e-01 -1.0289e-01  1.0849e-01\n",
      " -4.9681e-01 -2.5128e-01  8.4025e-01  3.8949e-01  3.2284e-01 -2.2797e-01\n",
      " -4.4342e-01 -3.1649e-01 -1.2406e-01 -2.8170e-01  1.9467e-01  5.5513e-02\n",
      "  5.6705e-01 -1.7419e+00 -9.1145e-01  2.7036e-01  4.1927e-01  2.0279e-02\n",
      "  4.0405e+00 -2.4943e-01 -2.0416e-01 -6.2762e-01 -5.4783e-02 -2.6883e-01\n",
      "  1.8444e-01  1.8204e-01 -2.3536e-01 -1.6155e-01 -2.7655e-01  3.5506e-02\n",
      " -3.8211e-01 -7.5134e-04 -2.4822e-01  2.8164e-01  1.2819e-01  2.8762e-01\n",
      "  1.4440e-01  2.3611e-01]\n"
     ]
    }
   ],
   "source": [
    "# Here is a overview of how to use the embeddings.\n",
    "\n",
    "# Generate fake test news to see how embedding works\n",
    "test_news = \"This is some test news\"\n",
    "\n",
    "# This create a list of numbers. Each number corresponds to the index of its embedding in the embedding lookup\n",
    "print(getArticleMatrix(test_news))\n",
    "\n",
    "# See the indexes match\n",
    "print(wordsList.index(\"this\"))\n",
    "print(wordsList.index(\"is\"))\n",
    "print(wordsList.index(\"some\"))\n",
    "print(wordsList.index(\"some\"))\n",
    "print(wordsList.index(\"test\"))\n",
    "print(wordsList.index(\"news\"))\n",
    "\n",
    "# The embeddings dictionary lookup, also matches the index lookup\n",
    "print(model['this'])\n",
    "print(embeddings[wordsList.index(\"this\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3791,   1155,  25058,      6, 399999,   3187,   3791,   1155,\n",
       "        49070,      3,      0,    920,   8775,    172,   2557, 399999,\n",
       "            5,   1551,      3,      0,   3791,   1155,    273,     31,\n",
       "           51,  25058,      6,     26,   1267,   3336,      0, 284841,\n",
       "       399999,   3187,   1155,      5,    423,   8323,    906,     76,\n",
       "           62,     12,    220,    590,    165,    148,     35,    791,\n",
       "            6,      7,   9520,  27478,    964,   1739,   6123,      5,\n",
       "        10711,   2930,    622,      0,    289,   8038,   9388,  20594,\n",
       "        14805,  13376,  29948,   9388,     19,      7,    669,      0,\n",
       "         2196,   8395,      0,    590,    165,      5,    107,     33,\n",
       "         1098,   1034,   1441,      4,      0,   4539,    443,    763,\n",
       "          398,    220,     95,    347,   2255,     33,    114,   1311,\n",
       "           12,     39,     33,  12784,    109,      3,    158,   1267,\n",
       "           49,  16379,   4815,     13,      0,   2087,      3,    201,\n",
       "            3,      0,    638,    479,    840,     32,    287,      4,\n",
       "           30,   1450,      6,      0,    781,    249,      0,    172,\n",
       "          934,     19,      7,   3143,  27799,     10,   1155,     38,\n",
       "           31,     51,    876,     21,    109,   4826,    493,   7001,\n",
       "            3,    134,      7,   4642,  27285,      5,      3,   3648,\n",
       "         6412,    172,   6380,   1155,     31,    456,   2571,   3187,\n",
       "            5,     15, 121250,      6,    493,    687,     19,     29,\n",
       "          880,      3,    197,  14535,      5,  10747,    172,  44460,\n",
       "           13,    659,    493,   9986,    117,   8320,   8364,      5,\n",
       "        10360,    105,      0,  15463,    367,   1155,     31,     52,\n",
       "         4497,  27972,      6,      0,    239,     78,   2189,      3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the resulting embedded news\n",
    "embedded_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
